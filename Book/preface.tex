
This is a book on statistical computing, or what might now be better
termed \textit{information} technology.  The focus we have is on
aspects of computer science and data technologies that are part of the
everyday world of statisticians.  This involves topics like databases;
text manipulation; data acquisition; programming logic, models and
style and so on.  These are the topics often covered in computer
science classes.  Unfortunately, these classes are rarely taken by
statisticians who typically follow a more mathematically oriented
curriculum.  Also, the computer science view of these topics does not
frequently include aspects relating to data and statistical analysis,
and the general ideas of using these technologies for statistical
purposes.  In other words, often the stuents don't understand the
purpose of these technologies and how they relate to the application
of statistics.  The goal of this book is to try to convey the ``big
picture'' view of these technologies from the perspective of their use
in applied statistics and to provide a basic understanding of how they
are used and how they work.  The content is not intended to be
exhaustive and extremely detailed.  It is a survey of the important
introduction concepts to a collection of technologies.  It will
hopefully whet the appetite of student and instructor alike to
discover more about topics that are of particular interest to him or
her.

The selection of topics to include has been difficult.  The last 15
years of computing has been quite spectacular in terms of the advent
of new technologies.  The Web is of course the most remarkable and has
fostered and nurtured many different technologies that exploit its
almost ubiquitous presence.  There are many other topics we might
include.  We have elected not to for a variety of reasons.  Firstly,
we can only write so much and we feel it is more beneficial to publish
a smaller book quickly than a comprehensive book several yuears from
now (at best!).  The dynamic and ever-changing nature of the material
makes this especially true. Most importantly, however, there is no
similar texbook available at present, to the best of our knowledge.
And there is a glaring need for statisticians to master this material
to be of most use in applied statistics. We feel that it is important
that our students - both undergraduate and graduate - have the skills
to involve themselves in the entire process of scientific and
statistical work rather than relying on being given data at intervals
and presenting analysis or results outside of the dynamic decision
making and discovery of modern exploration.  Essentially, science and
statistics is changing to be inter-disciplinary.  We need
statisticians to be active in all aspects of design, data acquisition,
analysis and presentation and that requires skills in many domains, or
at least a rudimentary understanding of the different domains and the
essential components of each.  We also very much want our students to
be self-sufficient in terms of finding interesting data-related
problems themselves and not relying on others to suggest interesting
research topics and questions and also provide data.  Computer
technology has made access to certain types of data relatively easy.
Not only can we use the Web to access data such as genome sequences,
etc. but computers themselves are the source of very interesting data.
Web logs, mail exchange records, network traffic, software itself are
data that can provide answers to very interesting questions.


A second reason for omitting certain topics such as programming in
C...  is because we feel that that is a specialization or an
optimization that can be left to students for whom it is most
relevant.  Instead, want the students to focus on learning broad
skills and understanding when and how they can be used.  We use
high-level languages to allow them o focus on the new topics.
Focussing on efficiency concerns introduces a different goal and can
cause the students to miss the point.
 
Many people would expect a statistical computing class to focus on
numerical computation.  We think of this as computational statistics -
the computational aspects of statistical methodology, or the focus on
computational details of statistics.  This is very different from
statistical computing which focuses on computing and computer science
and how it relates to statistics.  The two obviously go hand in hand,
but they are different.  Computational statistics is related to
numerical analysis, assumes computational and mathematical skills and
focusses on how computations are actually done.  It is an important
field, but we feel best left for specialized study in this current
era.  We believe this because high-level statistical software that
keeps these details below every day use is readily available. This
software encapsulates optimization of the code, special cases, etc.
that are hard to teach well in a one or two semest curriculum, but
which are essential for good, advanced computing in this field.  For
students who are interested in this field, the availability of
specialized books, Open Source libraries and applications provides a
real study of the area.  Books such as Lang, Chambers, Thisted \& Gentle
cover this area well.


It is helpful to think about what we would like the reader to come
away with from the book.

At its simplest, we want the students to have both the knowledge and
confidence to approach a problem involving data so that they can
extract information from the data.  In many cases, this will be start
and perhaps even end with exploratory data analysis (EDA).

Skills in writing software,
understanding of different technologies and their roles,
ability to be able tackle a problem involving
non-traditional data sources, 
simulation,
visualization 



\section{Prerequisites}
It hardly makes sense to introduce the bootstrap
without the students understanding the concept of
a statistic.
It hardly makes sense to introduce 


\section{What Students might know.}

It is important to understand why we are studying data technologies
within a statistics curriculum.  A statistician needs to be able to
participate in each step of the scientific process: generating
hypotheses(?), designing experiments, gathering data, ``cleaning''
(validating) data, managing data (databases), exploring data, modeling
data, and reporting results.  We typically teach only the elements of
modeling and to some extent the exploration (EDA).  Designing
experiments is less commonly taught these days, with preference going
to more modern modeling methodologies (MMMs!).  Resarch statisticians
have often found it difficult to obtain interesting data, being at the
mercy of colleagues in other disciplines to provide example datasets.
Not only does this bias the validation of the research, it also
constrains the research by creating a bottleneck: the statistician
must wait for the colleague to provide data in a suitable form.  The
incentives may not make the delivery rapid.

With the phenomenal growth in computer-generated and stored data,
finding interesting example datasets is now much easier.
Statisticians that can




