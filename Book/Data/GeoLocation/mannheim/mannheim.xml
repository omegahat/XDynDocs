
Look at the distribution of orientations
for both the offline and online separately, initially.
<answer>
plot(as.numeric(names(x)), x)
</answer>
What are the interesting characteristics?		       
<!--wrap around from 360 to 0-->
Are the two distributions the same?
<answer>
x = table(off$orientation)
y = table(on$orientation)
plot(as.numeric(names(x)), x/nrow(off))
points(as.numeric(names(y)), y/nrow(on), pch = "+", col = "red")
</answer>


<answer>
roundOrientation
</answer>

How many devices are there in the entire system?
And what sort of devices are they.
<!-- mode -->
<answer>
table(off$mode)
So 20% adhoc, 80% access points.
Check it by individual test point also
to get a distribution.
z = sapply(ref, function(x) table(x$mode))
summary(z[1,]/z[2,])
</answer>

How many reference points are there and
how many observations at each reference
point?
<answer>
ref = by(off, list(off$x, off$y), function(x) x)
ref = ref[!sapply(ref, is.null)]
length(ref)
sapply(ref, nrow)
</answer>
What is the distribution of orientations at
each reference point?
<answer>
Need to group into clusters of 45 degrees.

ref.orientation = sapply(ref, function(x) table(x$orientation))
</answer>
How can we display this graphically.
<!-- radial/starplots -->
How many different orientations are there at each reference point.


Look at signal strength to each of the access points 
for each reference point.
<!-- at each reference point, draw the distribution of signal strengths
     to each of the 6 access points with the "110" observations 
     for the 8 different orientations.
-->



A model for predicting location from a collection of signal strengths
and orientation is something like the following:

We look at the orientation of the new measurement
and we consider all the training data that has
a similar orientation, i.e  
$\vert o_{\textrm{training}} - o_{\textrm{test}} \vert < \alpha$

If we choose $\alpha$ too small, we will have very few training
observations to use for predicting location.  If we choose $alpha$ to
large, we will include a lot of less relevant training data,
i.e. those that are facing in the opposite directions and so will
introduce more variability.  So we need to find the "optimal" value/range
for $alpha$.

Within this subset of training data, we don't simply take the location
of the observation that is closest in signal strength distance.
Rather, we might take an average of the positions of the closest $k$
training observations.  So we need to determine $k$.  And rather than
taking a simple average, we may want to compute the weighted average
where we weight more highly values that are closer in signal strength
distances. This makes sense as we are borrowing strength from several
observations, but still allowing some flexibility for the most influential
ones to determine the location more precisely.
Which weighting scheme works best - equal or inverse distance?

Implicitly, we have assumed a notion of distance between signal
strengths from the new observation to each of the training
observations.  Firstly, we collapse the training observations into a
mean.  Or should we use a median? How should we determine this?  Then
we might use euclidean distance, i.e.  or we could use another measure
such as the manhattan metric which is the sum of the absolute values
of the differences of the terms in our vector.  Alternatively, we
might use euclidean distance but transform the signal strenghts using,
e.g. log or sqrt, to make them more "appropriate" for stabilizing
variance or making more "Normal".




We use cross validation to determine the values
of $alpha$, $k$ and which weighting scheme works best.
We have both an off-line and an on-line data set.
This gives us more possible ways to perform the cross validation.
We can break the on-line data into $v$ parts, and keep the
off-line data fixed.  Alternatively, we might think about 
breaking the off-line dataset into training and test parts.
This makes less sense.


Having determined values for these parameters, we can see how well we 
do for each of the different testing points.
Is there a spatial pattern  to the errors,
i.e. do we do better in the middle and worse at the edges
of the building? or is it harder to estimate correctly positions in corridors ?
Do we do better when there are more reference points?

We would like to reduce the time to construct the reference points.
So rather than having 166 reference points 
with 110 observations for several orientations,
we would like to reduce the overall number of observations.
Can we achieve similar predictive accuracy
reduce 


Getting things from the database

con = dbConnect(dbDriver("MySQL"), dbname = "Mannheim", host = "gcox.ucdavis.edu")
system.time(z  <- dbGetQuery(con, "select AVG(signal), x, y, orientationLevel, mac  FROM offline WHERE mode = 'access_point' GROUP BY mac, x, y, orientationLevel;"))



Plot the signal strength for the top left AP for different orientations
and we can see that the 3rd to last orientation (225 degrees) has no 

xyplot(y ~ x | orientationLevel, off[ off$mac == rownames(AP)[1], ], groups = cut(signal, 7), auto.key = list(columns = 7),
       xlim = range(c(-1, AP[,1])), ylim = range(c(0, AP[,2])),
       panel = function(x,y, ...) {
          ltext(AP, labels = gsub("^([a-f0-9]{2}:){4}", "", rownames(AP)))
          panel.xyplot(x, y, ...)
       })


pts = by(off[, c("x", "y")], off[, c("x", "y")], function(x) x[1,])
pts = pts[!sapply(pts, is.null)]
ref.pts = matrix(unlist(pts), , 2, byrow = TRUE)


v = rbind(AP, ref.pts)
refAP.dist = as.matrix(dist(v, "euclidean"))[1:6, -(1:6)]



off$orientationLevel = roundOrientation(off$orientation)
off.AP = off[off$mac %in% rownames(AP),]
by(off.AP, list(off.AP$mac, off.AP$orientationLevel, factor(paste(off.AP$x, off.AP$y))), function(x) structure(c(mean(x$signal), x, y), names = c(x["mac"], "x", "y"))))



means =
apply(pts, 1, function(p) {
                  sapply(rownames(AP), function(ap) {
                           z = off[off$x == p[1] & off$y == p[2] & off$mac == ap,] 
                           with(z, by(signal, orientationLevel, mean))
                        })
              })

with(off[off$mac %in% rownames(AP),],
     by(data.frame(signal, x, y, orientationLevel, mac), list(orientationLevel, mac, x, y),
           function(x) {
              c(mean(x[,1]), x[1,2], x[1,3], x[1,4], x[1,5])
           }))

off.AP = off[off$mac %in% rownames(AP),]

means = with(off.AP, by(off.AP, list(orientationLevel, mac, x, y), function(x)mean(x$signal)))




Draws the densities for each of the "110" signal strengths
for each combination of  reference point (in the second one below), access point target
and orientation.


# This is just for one reference point, the first.
a = off[ off$x[1] == 0 & off$y[1] == 0,]
plot(0, xlim = range(a$signal), ylim = c(0,.7), type = "n")
invisible(with(a[a$mode == "access_point",], by(signal, list(orientationLevel, mac), 
          function(x) {
              if(length(x) > 1)
               points(density(x), type = "l")
          })))

plot(0, xlim = range(off$signal), ylim = c(0,.7), type = "n")
invisible(with(off[off$mode == "access_point",], 
               by(signal, list(orientationLevel, mac, x, y), 
                 function(x) {
                   if(length(x) > 1)
                     points(density(x), type = "l")
                 })))



invisible(with(off[off$mode == "access_point",], 
               by(off, list(orientationLevel, mac, x, y), 
                 function(x) {
                   if(length(x) > 1)
                     points(density(x), type = "l")
                 })))


We think based on the number of observations
containing these MACs and that they have a very low
signal strength, that these are outside of our
6 APs.

00:04:0e:5c:23:fc  (and same story with 'offline')
00:0f:a3:39:e0:4b
00:0f:a3:39:e2:10


02:42:1c:4e:b5:c0
00:30:bd:f8:7f:c5
00:e0:63:82:8b:a9 


plot(y ~ x, off, xlim = range(AP[,1]), ylim = range(AP[,2]))
text(AP, gsub("^([a-f0-9]{2}:){4}", "", rownames(AP)), cex = 1.3, col = "red")


brewer.pal(6,"Spectral")

f =
function(x, y)
{
  d = off[off$x == x & off$y == y & off$mac %in% rownames(AP),]
  z = with(d, by(d[, c("signal", "mac", "orientationLevel")], list(orientationLevel), 
           function(s) {
              mu = by(s$signal, s$mac, mean)
              mu[!sapply(mu, is.na)]

           }))
  z = z[!is.null(z)]
  z
}
  

}

function(x, y, ap.names)
{
  by(signal, list(orientation, mac)
  for(i in 1:nrow(AP)) 
    lines(c(x, AP[i,1]), c(y, AP[i,2]), )
}