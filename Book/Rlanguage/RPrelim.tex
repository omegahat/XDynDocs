	
\chapter{The R Programming Language}
\label{chap:RIntro}
This chapter introduces some of the core ideas in the R programming
language and environment and shows how to use it. We provide a broad
picture of the language rather than an exhaustive view.  The aim is to
uncover the rationale of the language. R is a terrific, interactive
medium with which you can hypothesize and test characteristics, and we
expect the reader to explore the ideas interactively using the R
environment as they read this chapter and experiment with how the
language works. Finding out how R works and learning to think about
how to express computations in R will greatly simplify your future
work. It is good to take the time early on to learn a language and not
simply use it in a utlitiarian, ad hoc manner. While R is a specific
language that you may or may not use extensively in the future, it is
important to realize that what you learn when exploring R will be
generally applicable to many different programming languages that you
might use.


\section{Getting Started}
We first start R by invoking the command \verb+R+ at the command line
or by launching the R user interface.  
{\footnotesize{
\begin{verbatim}

R version 2.7.1 (2008-06-23)
Copyright (C) 2008 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

[Previously saved workspace restored]
> 
\end{verbatim}
}}
Note the line that says:
\begin{verbatim}
[Previously saved workspace restored]
\end{verbatim}
This means that R is loading up the data that was saved from the
last R session.

R is both an interactive and interpreted language. By interpreted, we
mean that we can give an instruction and immediately have it
evaluated. Then, we can give another command.  R has lots of functions
(over 1500 immediately available to you and thousands more in add on
packages). It is impossible to remember all of these and their details
(e.g. what arguments they take, what they do in all situations and
what they return) and to make effective use of R, you need to get into
the habit of using the help system. (One way to get help is to type
\verb|help("topic")| to get help on the specified topic.)

In this chapter we present the basic building blocks in R that you
have available to you.  R is a programming language that is
statistically focused. It is a good tool to know for doing any kind of
data analysis. To use it effectively, you will need to understand
these basics and to gain experience with the engine and the numerous
functions.

One way to use R is as a heavyweight calculator. 
\begin{verbatim}
> 1+2
[1] 3
\end{verbatim}
Like a calculator, R has built-in values, such as \SVariable{pi}. 
\begin{verbatim}
> 1+pi
[1] 4.141593
\end{verbatim}   
In R, the \SVariable{pi} ``thing'' in this computation is a
variable. By this we mean it is a name by which we refer to a
value. We can associate new values with this name by
{\em{assigning}} a value to it. For example, we can give
\SVariable{pi} the value 1 and then use that.
\begin{verbatim}
> pi = 1
> 1+pi
[1] 2
\end{verbatim}
So \SVariable{pi} is not a constant in this world. Mathematically, it
is, but in the programming world, it is merely a variable to which we
can bind or assign new values. Of course, this is not necessarily a
good idea. If we use this new value for $\pi$, we will get strange
results!

There are several ways to assign a value to a variable in R. They
differ only in syntax.
\begin{verbatim}
> x = 1+2
> x <- 1+2
> 1+2 ->x
> x
[1] 3
\end{verbatim}
These three forms (=, \textless{}-, and -\textgreater{}) can all be
used, however the last is very rarely seen. It arose when one was
typing a long command and realized that we had forgotten to assign the
result. At one time, we couldn't go back to the beginning of the line
without deleting all the intervening text and so removing the
command. Nowadays, we can jump to the beginning of the line, and add
the assignment and continue on. In reasonably recent versions of R,
one could also use the underscore (\_) as the assignment
operator. This is no longer possible and soon we will be able to use
it as a character in a variable name. So the following error occurs
when we try to assign using \_ now:
\begin{verbatim}
> x_ 1
Error: syntax error
No suitable frames for recover()
\end{verbatim}


Now that we can create variables, we can do some useful things, and we
may want to ensure that we don't lose anything we do. It is a good
time to think about how we might save our data. Each time we run R, we
create a new R session. Then we can do some work, create new variables
and potentially want to save some or all of them. We can save our
entire workspace, i.e. all the variables we have created calling the
function the \SFunction{save.image} at any time. This puts all the
objects in our session workspace into a file named .RData. If we
start R again (in that directory), the contents of that .RData are
loaded into the new session and are immediately available to us
again. If we start in a different directory, we can still load the
values into the R session, but we must do this ourselves using the
function \SFunction{load} and giving it the fully qualified name of
the file to load (i.e. full directory path and file name).

When we end the R session using the \SFunction{q} function, we will
normally be asked whether we want to save the session or not. This
calls \SFunction{save.image} implicitly.

If we don't want to store all the variables, but only specific ones,
we can explicitly \SFunction{save} one or more objects to a file (or
generally a connection). This is convenient when we create a big
dataset and then want to ensure that it gets saved before we do
anything else. Or if we want to make an object available to another R
session, e.g. to somebody we are working with, without terminating
ours, we can simply write the object to disk and then send it that
person in an entirely portable format.

Note that R uses "copying" semantics. When we assign the value of
\Svariable{x} to \Svariable{y}, \Svariable{y} gets the value of
\Svariable{x}. It is not ``linked'' to \Svariable{x} so that when
\Svariable{x} is changed, \Svariable{y} would see that
change. Instead, we copy the value of \Svariable{x} in the assignment
and the two variables are unrelated after that.
\begin{verbatim}
> x
[1] 3
> y = x
> x = 10
> x
[1] 10
> y
[1] 3
\end{verbatim}
We have seen how we can store the results of computations or simple
values in variables. We can think of these as being stored in our
workspace. This is like our desk with pieces of paper storing
different information. We would put different pieces of paper in
different places so that we can easily find them again when we need
them. The place we put them allows us to quickly find them and is
analogous to the variable name which allows us to easily refer to the
values.

In the same way that we might overload our desk with pieces of paper
as we move from task to task, or just have too much information, we
need to manage the variables we have in our work area or desktop. R
provides functions which we can use to dynamically manage the
variables and the contents of our workspace. The function
\SFunction{objects} gives us the names of the variables we have in our
workspace.
\begin{verbatim}
> objects()
[1] "x"  "y"  "pi"
\end{verbatim}
We can remove values using \SFunction{remove} by passing the name to
the function of the variable we want to remove.
\begin{verbatim}
> remove("x")  
\end{verbatim}
and we can verify that the variable has been removed using
\SFunction{objects} again.
\begin{verbatim}
> objects()
[1] "y"  "pi"
\end{verbatim}
We can give more than one name. So we can remove both \SVariable{y}
and \SVariable{pi}, the last two remaining variables in our
session's workspace.
\begin{verbatim}
> remove("y", "pi")
\end{verbatim}
Before we leave this topic, we should ask what happened to the
original version of \SVariable{pi}? We assigned a new value to it - 1
- and used that in our computations? Now that we removed it, is
\SVariable{pi} defined at all?  Is the old value put back? The answer
is that the old value is now in effect again, but it wasn't ``put
back''. R did not remember the old value and restore it when we removed
our version of \SVariable{pi}. The explanation is a little more
complicated, and a lot richer. It relates to where we were finding the
variable named \SVariable{pi}.

When we issued the command 
\begin{verbatim}
> pi = 1
\end{verbatim}
we were telling R to associated the value 1 with the variable name
\SVariable{pi}. This puts it in our workspace. But before we did this,
we managed to find \SVariable{pi} also, and then it had the usual
value of 3.141. So where did it come from? It wasn't in our workspace,
yet it was still available.

The answer involves understanding how R finds variables when we refer
to them. R actually keeps a collection of places in which to search
for variables. This is called the search path. This is an ordered
collection of workspaces containing variables and their associated
values. At any point during an R session, we can ask R what this
collection of workspaces is. We do this using the function
\SFunction{search}. In this session, we get
\begin{verbatim}
> search()
[1] ".GlobalEnv"     "package:Rbits"    "package:methods" 
[4] "package:stats"  "package:graphics" "package:utils" 
[7] "Autoloads"      "package:base"    
\end{verbatim}
The first entry is our own personal workspace. When we quit, this
disappears. The other entries are packages or libraries of functions
and data that are available to us.

Now, when we implicitly cause R to look for a variable, it walks along
this collection and asks each entry whether it has the relevant
variable. After we defined our own version of \SVariable{pi}, when we
used \SVariable{pi} in a computation such as \verb|1 + pi|, R started
its search for \SVariable{pi}. It started in the first element of the
search path, and found it there. That is our workspace where put
\SVariable{pi}.

 When the session started and we did not yet have our own version of \SVariable{pi}, the search for \SVariable{pi} was rather different. R looked through each element of the search path and found \SVariable{pi} only in the last entry "package:base". This contains the built-in variable provided by the R system itself (rather than add-ons). 

 How could we know where R would find a variable? We can use the function \SFunction{find}. So in the following, we define \SVariable{pi}, and ask R where we can find it. 
\begin{verbatim}
> pi = 1
> find("pi")
[1] ".GlobalEnv"   "package:base"
\end{verbatim}
Now, we remove our version of \SVariable{pi} and then R can only find the one in "package:base". 
\begin{verbatim}
> remove("pi")
> find("pi")
[1] "package:base"
\end{verbatim}
All the functions we have seen so far, and in general, are simply
values assigned to variables. R finds them in the same way when we
refer to them in a computation. It looks through the search path until
it finds the variable. It is slightly smarter for functions. If it
knows we are calling the value of the variable as a function, it will
only look for a function, skipping over other types of values.

What if we look for a variable that doesn't exist? For example,
suppose we use a variable named \SVariable{fred} in a computation
\begin{verbatim}
> fred^2
\end{verbatim}
What happens? R looks through each element of the search path and
eventually gives up, giving the error message:
\begin{verbatim}
Error: Object "fred" not found
\end{verbatim}
We can determine whether a variable is defined using \SFunction{find},
or using a more convenient function in some cases named
\SFunction{exists}. For example,
\begin{verbatim}
> exists('fred')
[1] FALSE
\end{verbatim}
(Note that you can use single or double quotes for a string,
i.e. \verb+"fred"+ or \verb+'fred'+.)


\section{The Basic Data Types}
In R, everything is an object. We have seen this already. We have
variables that refer to values, and functions which do things are
accessed as regular variables. So we see that we have a commonality
for data and functions. This is different from many languages such as
C/C++, Java, etc. For interpreted languages, it is quite common and it
is very powerful.

The basic or primitive types of objects are vectors. These are simply
collections of values grouped together into a single container. The
basic types are integer, numeric, logical and character vectors. A
very important characteristic of these vector types is that they can
only store values of the same type. In other words, a vector has
homogeneous data types. We cannot use a vector to store both an
integer and a string in their basic forms. (We'll see that we can put
them into a vector and the integer will become a string. Also, we can
use what is called a ``list'' to store them both in their original
form.)

As we just said, there are 4 basic types of vectors: integer,
character, numeric and logical. Integer vectors store integer values,
numeric vectors store real numbers, logical vectors store values that
are either TRUE or FALSE and character vectors store strings. In C and
Java, we can work on characters individually. However, in R there is
no way to store a single character except as a simple string with only
one character. This is very rarely a problem.

Essentially, vectors are like arrays in C and Java. In those
languages, there is a large difference between a scalar or basic
built-in value and arrays of such values. In R, there are no
scalars. By this, we mean that there are no individual number objects,
or logical values, or strings. Instead, such individual values are
actually vectors of length 1. So they are special cases of general
vectors with multiple elements. This makes lots of computations
convenient.

An important function for creating vectors is the \SFunction{c}
function. The `c' stands for concatenate, and all it does is take one
or more values and put them into a new vector. For example,
\begin{verbatim}
> c(1.2, 4.5, 3.2)
[1] 1.2 4.5 3.2
> c(TRUE, FALSE, FALSE, TRUE)
[1]  TRUE FALSE FALSE  TRUE
> c("Abc", 'def', "ghikllm", "z")
[1] "Abc"     "def"     "ghikllm" "z"      
\end{verbatim}
What about the integer vector? Well, in R, all numbers that we type
are made into real numbers. So when we type
\begin{verbatim}
> c(1, 2, 3)
\end{verbatim}
we get a numeric vector as the individual values are actually
numeric. (This is different in S-Plus, version 5 and higher.)

There are many cases in which we want integers and they arise
naturally. One of them, as we shall see in the subsetting section, is
a sequence of integers. The built-in syntax for creating the integer
sequence a, a+1, a+2, ..., b is \verb|a:b|. For example,
\begin{verbatim}
> 1:10
 [1]  1  2  3  4  5  6  7  8  9 10
> 4 : 5
[1] 4 5
> 10:3
[1] 10  9  8  7  6  5  4  3
> 3:3
[1] 3
\end{verbatim}
This is a very specific version of the more general \SFunction{seq}
function. This allows us to create sequences with different strides
(differences between successive elements), of specific length, and so
on. See the help pages.
\begin{verbatim}
> seq
function (...) 
UseMethod("seq")
<environment: namespace:base>
> seq(1, length = 10, by = 2)
 [1]  1  3  5  7  9 11 13 15 17 19
\end{verbatim}


An important characteristic of any vector is its length. We can always
find out how many elements a vector contains using the function
\SFunction{length}.
\begin{verbatim}
> x = 1:10
> length(x)
[1] 10
> letters
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o"
[16] "p" "q" "r" "s" "t" "u" "v" "w" "x" "y" "z"
> length(letters)
[1] 26
\end{verbatim}
Note that the return value from calling \SFunction{length} is itself a
vector. It is an integer vector of length 1. The system uses its own
built-in types to provide functionality.

Often we want to combine two vectors. We can also do this using the
\SFunction{c}.
\begin{verbatim}
> x = c(1, 2, 3)
> y = c(4, 5, 6)
> c(x, y)
[1] 1 2 3 4 5 6
\end{verbatim}
We can also use the function \SFunction{append}. Look at the help for
\SFunction{c} and \SFunction{append} and try to discover the
difference.

In many situations, it is convenient to associate names with elements
in a vector. For example, suppose we have IP addresses of machines
stored as strings. We might also want to associate the human-readable
name along with it. For example,
\begin{verbatim}
          wald          anson         fisher 
"169.237.46.2" "169.237.46.9" "169.237.46.3"
\end{verbatim}
Here, we have associated the names wald, anson and fisher with the
elements of the character vector.

For any vector, we can ask for the names of the elements. Suppose the
vector of IP addresses above was assigned to the variable
\SVariable{ip}, then we could get the character vector of names using
the function \SFunction{names}.
\begin{verbatim}
> names(ip)
[1] "wald"   "anson"  "fisher"
\end{verbatim}
If the vector has no names, we get back \textsl{NULL}. This is a
special symbol in R, and has length 0. We can check if a value is
\textsl{NULL} using \SFunction{is.null}:
\begin{verbatim}
 is.null(names(ip))
\end{verbatim}


There are several ways to specify the names for a vector (of any type,
i.e. integer, numeric, logical or character). If we are explicitly
creating the vector (using \SFunction{c}), then we can put the names
in the expression, as in
\verb|c("169.237.46.2", "169.237.46.9", "169.237.46.3")|.
\begin{verbatim}
> c(wald="169.237.46.2", anson = "169.237.46.9", 
   fisher = "169.237.46.3")
\end{verbatim}
If we already have a vector, then we can assign names to the elements
using the \SFunction{names} function (or technically the
\verb+names<-+ function).
\begin{verbatim}
> x = 1:26
> names(x) <- letters
a  b  c  d  e  f  g  h  i  j  k  l  m  n  o  p  q 
  r  s  t  u  v  w  x  y  z 
1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 
 18 19 20 21 22 23 24 25 26 
> y = c(0, 0, 256)
> names(y) = c("R", "G", "B")
> y
  R   G   B 
  0   0 256 
\end{verbatim}
Useful general facilities for operating on vectors are
\SFunction{rep}, \SFunction{rev}, \SFunction{sort}. \SFunction{rep}
allows us to replicate a vector in convenient ways.
\begin{verbatim}
> rep(c(1, 2, 3))
\end{verbatim}
For character vectors, \SFunction{paste} is convenient for combining
strings together. The function \SFunction{strsplit} can be used for
splitting strings by user-specified delimiters, and
\SFunction{substring} can be used to extract a sub-part of a
string. In additiona, we can match and substitute text using regular
expressions with the functions \SFunction{grep} and \SFunction{gsub}.

 
\section{Vectorized Operations}
In lower-level languages like C/C++ and Java, we operate on entire
arrays by iterating over each element. We have code something like:
\begin{verbatim}
 for(i = 0; i < n; i++) {
   f(x[i])
 }
\end{verbatim}
where \SFunction{f} is some function to do something on the individual
element of the array.

In R, since vectors are the basic types, and because in statistics we
typically want to work on groups of observations or experimental
units, the philosophy is that operations work on an entire
vector. This means users don't have to write loops for many
operations. A simple example is the + function. We can add two vectors
together element-wise using the + operation:
\begin{verbatim}
> c(1, 2, 3) + c(4, 5, 6)
[1] 5 7 9
\end{verbatim}
The first element of each vector are added together to get
5. Similarly, we get 7 and 9 by adding the second elements, and the
third elements.

This is very powerful and convenient. It allows us to express
computations at a high-level, indicating what we mean rather than
hiding it in a loop. Many functions in R are vectorized, meaning that
if you give them a vector of length n, they will operate on all n
elements rather than just the first one. \SFunction{strsplit} is an
example. If we give it the vector of IP addresses and ask it to break
the strings into sub-parts separated by ., then we get
\begin{verbatim}
> strsplit(ip, "\\\.")
$wald
[1] "169" "237" "46"  "2"  

$anson
[1] "169" "237" "46"  "9"  

$fisher
[1] "169" "237" "46"  "3"  
\end{verbatim}
Here, we get back a collection of character vectors. The collection
has the same names as the original input vector (wald, anson, fisher)
and each element is a string with the particular part of the IP
address. The actual data type of the result is a list which we shall
see shortly.

When you right your own functions, you should try to make them
vectorized so that they take in a vector and give back a value for
each element. Of course, if these are aggregator functions (e.g. sum,
prod, lm), then they should work on all of the elements and combine
them into a single result.


\section{The Recycling Rule}
What if we add two vectors with different lengths. For example, what
happens to \verb| c(1, 2) + 2|? We would like R to be smart enough to
add 2 to each element. That is what happens.
\begin{verbatim}
> c(1, 2) + 2
[1] 3 4
\end{verbatim}
What about \verb|c(1, 10) + c(100, 200, 300, 400)| where the second
vector has two more elements than the first.
\begin{verbatim}
> c(1, 10) + c(100, 200, 300, 400)
[1] 101 210 301 410
\end{verbatim}
R does the right thing, depending on what you think the right thing
is! But what did it do? It appears to have created the vector
\verb|c(1 + 100, 10 + 200 , 1 + 300, 10 + 400)| and indeed that is
what it did. This is a general concept in R; it recycles or replicates
the smaller vector to have the same length as the larger one. So, in
this case, we recycle \verb|c(1, 10)| to have length 4. We do this as
the function \SFunction{rep} would, basically by concatenating several
copies of the original vector to get the right length. So we get
\verb|c( 1, 10, 1, 10)| to have length 4, the same as the larger
vector and then we can do the basic arithmetic as before.

We can now understand how \verb|c(1, 2) + 2| works. 

What about the following expression \verb|c(1, 2) + c(10, 11, 12)|,
i.e. using vectors of length 2 and length 3.
\begin{verbatim}
> c(1, 2) + c(10, 11, 12)
[1] 11 13 13
Warning message: 
longer object length
	is not a multiple of shorter object length 
        in: c(1, 2) + c(10, 11, 12) 
\end{verbatim}
First thing to note is that R generates a warning telling you that you
may want to check whether the result is as you expected. The problem
is that recycling the smaller vector did not naturally yield a vector
of the same length as the larger one. That is why R gave a
warning. But it went ahead and did the addition using
\verb|c(1, 2, 1) + c(10, 11, 12)| as it recycled the smaller vector to
have the same length as the larger one and threw away any left over
elements.


 
\section{Subsets}
A lot of what we do in statistics and exploratory data analysis is to
look at subgroups of a sample or population. We determine
characteristics about that subset and compare them to other groups or
the same characteristic of the overall group. We might look at how
height and weight are related for both men and women separately. We
might look at milk yield for cows of different breeds. We might look
at stock prices within a particular week and so look at that
particular subset of time. We might also look at stock prices every
Friday rather than consecutive days. For Web page ``hits'' on a server,
we might look at the other requests from the site of the
requester. These are all examples of how we look at different parts of
our data using categorical or continuous variables to ``zoom in'' on a
subgroup. The criteria we use might be known ahead of time (type of
cow, male/female) or might depend on the data itself (e.g. other web
hits from the most frequent downloading site).

Being able to compute subgroups easily within our data is one of the
things that is most powerful in R, but also one that takes some time
to get used to. The flexibility comes from the fact that there are
many ways to specify the subset of interest and this can be
confusing. You should sit down and work with R to try to understand
what is happening and master the concepts. They are very useful. There
are essentially 5 different ways to subset a vector in R. They all use
the [ function or operator and the only differences are what you
specify as the value to use to identify the particular subset of
interest. We'll use the built-in vector of lower case letters of the
alphabet as our simple vector to illustrate the ideas.
\begin{verbatim}
> letters
 [1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" 
[16] "p" "q" "r" "s" "t" "u" "v" "w" "x" "y" "z"
\end{verbatim}


Let's start with the most obvious and simple one. Suppose we have a
vector with n entries. A common thing to ask is for one or more
elements identified by position. For example, we can ask for the 2nd,
5th and 10th elements. We do this by passing the positions of the
elements we want.
\begin{verbatim}
> letters[c(2, 5, 10)]
[1] "b" "e" "j"
\end{verbatim}
As we might have expected, we get back the specified elements of our
original vector. Note that what we get back is also a vector of the
same type as our original one, in this case a character vector. The
result has as many elements as we asked for in our specification of
the subset.

This is very simple: we ask for the values we want by identifying
their position. What if we give a position that makes no sense,
e.g. that is larger than the length of the starting vector. For
example, let's ask for the 30th element of the \SVariable{letters}
object.
\begin{verbatim}
> letters[30]
[1] NA
\end{verbatim}
The result is a missing value, NA. This makes sense in many
contexts. It is something we should be aware of so that we can
understand how NAs might be introduced into our computations.

There are two other values that might be considered meaningless. What
if we ask for the 0-th element?
\begin{verbatim}
> letters[0]
character(0)
> letters[c(0, 1)]
[1] "a"
\end{verbatim}
Essentially, R ignores a request for the 0-th element and doesn't
include a value in the result for that element. This means that the
result may not have as many elements as we asked for.

Now, what if we ask for a negative index? For example,
\begin{verbatim}
> letters[-c(1, 3)]
\end{verbatim}
is outside the range of the indices of the elements of
\SVariable{letters}. What does R do with such a request? (Try it and
see what happens.)

Negative numbers for subsetting mean to drop those elements. What
happens in the above example is that we get a new vector derived from
\SVariable{letters} with the first and third elements dropped or
removed.
\begin{verbatim}
> letters[-c(1, 3)]
 [1] "b" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q"
[16] "r" "s" "t" "u" "v" "w" "x" "y" "z"
\end{verbatim}
There are some restrictions on this. We cannot mix positive indices
and negative indices in a single subsetting call. In other words, we
cannot include some and omit others in one action. So
\begin{verbatim}
> letters[c(-1, -3, 5, 6, 7)]
\end{verbatim}
might seem reasonable to drop the first and third elements and include
the fifth, sixth and seventh. But if we give such a command, we get an
error
\begin{verbatim}
> letters[c(-1, -3, 5, 6, 7)]
Error: only 0's may mix with negative subscripts
\end{verbatim}
and it makes sense. We are saying "I want you to only include these,
but also exclude those". That is not a good way to give an
instruction.

So we have seen two ways to get subsets so far. Both involve
identifying the elements of interest by position or index in the
original vector and either including them in the result or excluding
them. One of the problems is that we have to know the indices of the
desired elements. This brings us to the next two subsetting
approaches.

We have seen that vectors can have names. If we subset a vector with
names, then we can refer to the elements we want in the subset using
these names. Let's suppose we have our vector of IP addresses
\begin{verbatim}
> ip = c(wald="169.237.46.2", anson = "169.237.46.9",
         fisher = "169.237.46.3")
\end{verbatim}
To get only wald and fisher, we pass a vector giving these names. 
\begin{verbatim}
> ip[c("wald", "fisher")]
          wald         fisher 
"169.237.46.2" "169.237.46.3" 
\end{verbatim}
So far so good. Note that we are passing a vector to the
\SOperator{[}. We can't just put in names like
\begin{verbatim}
> ip["wald", "fisher"]
\end{verbatim}
This would be two arguments to \SOperator{[} and this confuses it for
a simple, linear, one dimensional vector.
\begin{verbatim}
> ip["wald", "fisher"]
Error in ip["wald", "fisher"] : incorrect number of dimensions
\end{verbatim}
The error gives a hint that we might be able to do two dimensional
subsetting on other types of objects. See matrices and data frames
below.

Again, if we ask for a non-existent element, we will get an
\textit{NA} in the result.
\begin{verbatim}
ip[c("wald", "fisher")]
          wald           <NA> 
"169.237.46.2"            NA 
\end{verbatim}
We cannot use this style of subsetting to exclude elements. Think
about what
\begin{verbatim}
ip[-c("wald", "fisher")]
\end{verbatim} 
means when R interprets the command. While we can understand that we
mean to drop the wald and fisher elements, R first evaluates
\begin{verbatim}
-c("wald", "fisher")
\end{verbatim}
This is meaningless as the negative of a string doesn't make sense. So
the error comes from this part of the computation.
\begin{verbatim}
> ip[-c("wald", "fisher")]
Error in -c("wald", "fisher") : Invalid argument to unary operator
\end{verbatim}
What's the unary operator? It is the \SOperator{-} operator. 

So now we have covered three types of subsetting: indexing by
position, exclusion by position, indexing by name. The next one is to
use a logical vector to index the elements we want. Like names, this
is used when we don't know the position of an argument but know what
we are looking for. We give the \SOperator{[} a logical vector and R
returns the subset of the original vector containing the elements
corresponding to \textsl{TRUE} values in our logical
"indexer". Basically, this is like super-imposing our logical vector
over the vector being subset, and dropping all the values under the
\textsl{FALSE} elements, and keeping all the elements under the
\textsl{TRUE} values. In this way, it works like a ``mask''. A couple of
examples may make this clearer. The simplest and least interesting is
the following:
\begin{verbatim}
> x = c("a", "b", "c", "b")
> x[c(TRUE, FALSE, TRUE, FALSE)]
[1] "a" "c"
\end{verbatim}
Here, we just extract the first and third elements. 

Suppose we wanted to get all the elements that were equal to
\verb+"b"+. Remember, that R is a vectorized language with the recycling
rule. The command
\begin{verbatim}
 x == "b"
\end{verbatim}
returns a logical vector with as many values as there are in
\SVariable{x} and the result contains \textsl{TRUE}s and
\textsl{FALSE}s according to the condition.
\begin{verbatim}
> x == "b"
[1] FALSE  TRUE FALSE  TRUE
\end{verbatim}
Now we can use this to subset \SVariable{x} to get all the ``b''
elements:
\begin{verbatim}
> x[x == "b"]
\end{verbatim}
This reads as ``get all the elements of x such that x is equal to \verb+'b'+''.

There are several other ways to do this subsetting. We could find the
positions of all the ``b'' elements and then use the positions as our
subsetting vector. This can be done in one command as
\begin{verbatim}
> x[(1:length(x))[x == "b"]]
\end{verbatim}
Think about what this is doing to make certain you understand it. We
can do the computations separately and look at the intermediate
results to see what is happening.
\begin{verbatim}
> x == "b"
[1] FALSE  TRUE FALSE  TRUE
> 1:length(x)
[1] 1 2 3 4
> c(1, 2, 3, 4)[c(FALSE, TRUE, FALSE,  TRUE)]
[1] 2 4
 x[c(2,4)]
[1] "b" "b"
\end{verbatim}
So we see that it does give us the same result. But compare the two
commands
\begin{verbatim}
> x[x == "b"]
> x[(1:length(x))[x == "b"]]
\end{verbatim}
By the way, why do we put the parentheses around \verb|(1:length(x))|?
Try it with and without and see what you get.

Let's look at another example. R has many functions to generate random
values from different probability distributions. One of the
distributions it doesn't support is what is called the ``truncated
normal''. This is a regular Normal distribution that is limited to
values between $a$ and $b$, where these are parameters specifying the
distribution. Suppose we want to generate values from such a
distribution, how would we do it? One approach is to sample from the
associated Normal distribution using the \SFunction{rnorm} function
and then discard any values that are less than a and greater than
b. In other words, we keep only the values in the interval $[a, b]$. We
can do this by simple subsetting using a logical vector. Let's suppose
we use a standard normal, $N(0, 1)$, and $a$ and $b$ are $-.1$ and $.3$,
respectively.
\begin{verbatim}
> x = rnorm(100, mean = 0, sd = 1)
> x[x < .3 & x > -.1] 
\end{verbatim}
Make certain you use the element-wise operator \& and not the other
form - \&\&.

Note that we can readily use logical vectors to exclude certain
elements rather than include them. Just like we negate the indices
giving positions to exclude values when subsetting, we can negate the
\textsl{TRUE}s and \textsl{FALSE}s easily. The \SOperator{!} does
exactly this. So if we want to drop elements specified by a logical
vector \SVariable{i}, we need do only the following:
\begin{verbatim}
> x[ !i ]
\end{verbatim}
Again, go through the intermediate computations, looking at
\SVariable{i} and \verb|!i| to see what is actually happening.

So now we have seen four ways to subset: inclusion and exclusion by
position, names and logical ``masks''. We said at the outset there were
five, so we only have one remaining and this is a special, degenerate
one. What if we pass no value for the indexing vector, i.e.
\begin{verbatim}
> x[ ]
\end{verbatim}
The result is \SVariable{x} itself, i.e the original vector. This is
not the same as passing in a vector with length 0
\begin{verbatim}
> x[integer()]
\end{verbatim}
That gives back a subset of \SVariable{x} with the same length as the
indexing vector and so is
\begin{verbatim}
> x[ integer() ]
numeric(0)
\end{verbatim}


Why is the empty subsetting (\verb|x[]|) useful and why are we making
a big deal of it? There are several reasons. One of the things we
haven't mentioned about subsetting until now is that not only can we
access sub-vectors using these five techniques, but we can also modify
the elements in the original vector by simply assigning elements to
the specified subset. We use the same subsetting on the left hand-side
of an assignment as we did earlier but specify an object on the right
side and good things happen.
\begin{verbatim}
> x = c(1, 2, 3)
> x[c(1, 3)] <- 10
> x
[1] 10  2 10
\end{verbatim}
Similarly, if we want to replace all the ``G''s in a character vector
with a string ``GG'', we can do this simply
\begin{verbatim}
> x = c("A", "G", "C", "C", "G", "G", "A")
> x[x == "G"] <- "GG"
\end{verbatim}
If we realized that we had made a mistake and erroneously switched the
IP addresses of anson and wald, we could switch them back via
\begin{verbatim}
> ip = c(wald="169.237.46.2", anson = "169.237.46.9", 
         fisher = "169.237.46.3")
> ip[c("wald", "anson") ] <- ip[c("anson", "wald")]
> ip
          wald          anson         fisher 
"169.237.46.9" "169.237.46.2" "169.237.46.3" 
\end{verbatim}
Note that the recycling rule is in effect in all of these cases. The
number of values on the right must match the number of values expected
on the left hand side and the recycling rule works to do this.

So what does this have to do with the empty subsetting capabilities?
Well, what's the difference between
\begin{verbatim}
> x <- 0
> y[] <- 0
\end{verbatim}
In the first case, we are assigning the value 0 to the name ``x''. In
the second case, we are assigning 0 to each element of the vector
\SVariable{y}.

Another reason why the empty subsetting is useful is when we deal with
multi-dimensional vectors, i.e. matrices and arrays. For these, we can
say "give me all the columns for the first four rows" as
\begin{verbatim}
> m[1:4, ]
\end{verbatim}
The same subsetting rules apply for each dimension and so we need a
convenient way to say ``everything'' in this dimension. And that is the
empty subsetting operation.

 
\section{Lists and Data Frames}
So far we have looked at vectors and we have emphasized that they must
have the same type of elements. If we try to combine different types
of elements, R coerces them to an appropriate common type. For example
\begin{verbatim}
> c(1, 1.2, TRUE, "abc")
[1] "1"    "1.2"  "TRUE" "abc" 
\end{verbatim}
results in a character vector. You can try combining different
elements and see what you get, e.g.
\begin{verbatim}
> c(as.integer(1), 1.2)
\end{verbatim}


There are so many situations that we want to be able to group values
with different types. An observation may be made up of an identifier
such as a name or social security number; age; day, month and year of
birth; gender; height; 3 measures of blood pressure; etc. We most
definitely don't want to put these into a vector as then everything
will have to be a string. We will throw away good information about
the fact that some are numbers, some are integers, etc. Instead, we
want to be able to group them together but keep their different
types. Otherwise, if we want to take the mean of the blood pressure
measurements for each person, or find the average height, we would
have to convert the strings to numbers, handle errors in the data that
had snuck in because we were treating numbers as strings and hadn't
verified that they were numbers, and so on. Generally, giving up
information about the type of a value is a bad idea. This
{\em{meta-information}} can be important, and is becoming much more
commonly available in data analysis and good programming these days.

So what we need is a container to group things together that supports
elements with different types. This is exactly what a list does in
S. A list is essentially a vector but can support elements with
different types. We put things into a list using the list function:
\begin{verbatim}
> x = list(1:10, "B", 
          list(name = "Joe Smith", ssn = "999-99-9999"), 
          rnorm(20))
\end{verbatim}
This shows that we can use any R object as an element in a list,
including lists themselves. We can use names for elements of lists as
we did for vectors.

We can use the same style of subsetting as we did for vectors
also. For example, we can get the first two elements of our list above
as
\begin{verbatim}
> x[1:2]
\end{verbatim}
And we can drop elements using negative indices:
\begin{verbatim}
> x[-1]
\end{verbatim}
Similarly, names and logical vectors will work the same way as they
did for vectors. What is important to note is that, just as for
vectors, the \SOperator{[} returns an object of the same type as the
one being subsetted. So using the \SOperator{[} on a list means that
we will get back a list. This is true even if the subset only has one
element. So if we want to get an element itself, rather than a list
containing that one element, we are going to need some other
mechanism. For example, consider the simple list
\begin{verbatim}
> x = list(1, "a")
\end{verbatim}
containing just two elements.  Next, we get the subset containing the
first element.
\begin{verbatim}
> x[1]
[[1]]
[1] 1
\end{verbatim}
It is a list of length 1, which is the same as the following.
\begin{verbatim}
> x[1][1]
\end{verbatim}


So we need another operator to extract an individual element. We use
\SOperator{[[} for this.
\begin{verbatim}
> x[[1]]
\end{verbatim}
Other than this and the fact that we can hold arbitrary types in a
list, they are like vectors. The same subsetting works. Elements can
have names. One thing we can do is use the \$ to access
elements by name. If we have a list
\begin{verbatim}
> x = list(sample1 = rnorm(10), sample2 = rnorm(1000))
\end{verbatim}
we can access the elements as
\begin{verbatim}
> x$sample1
> x$sample2
\end{verbatim}
We can apply a function to each element of a list using the function
\SFunction{lapply}, for ``list apply''. This works very much the same
way as \SFunction{apply} does for vectors/matrices. We give it the
list or vector and the function to apply to each element. The result
is itself a list where each element is the result of applying the
function to the corresponding element in the original list. For
example, with our list above containing two samples of observations
from a random normal distribution, we can calculate the sum and mean
of the values as
\begin{verbatim}
> lapply(x, sum)
$sample1
[1] -6.707135

$sample2
[1] 0.0317475
> lapply(x, mean)
$sample1
[1] -0.6707135

$sample2
[1] 0.00317475
\end{verbatim}
Note that the names of the new list are the same as that of the original list. 

If we want to save looping over the list twice, we could compute both
the sum and the mean in a single call.
\begin{verbatim}
> lapply(x, function(x) c(sum = sum(x), mean = mean(x)))
$sample1
       sum       mean 
-6.7071349 -0.6707135 

$sample2
       sum       mean 
0.03174750 0.00317475 
\end{verbatim}
This shows that we can specify a function either by name or by
defining one in our call. These are often called ``anonymous functions''
since they have no name.  In either case, the argument is a
function object and that is important. In some cases, we naturally
define a new function so that we can customize a particular. For
example, suppose we want to loop over a list in which each element is
a collection of lines. These might be mail messages, directory
listings, etc. Suppose we want to paste the elements of each
character vector together. If we had just one character vector, we would
use the \SFunction{paste} function with the \SArg{collapse}
argument. For example,
\begin{verbatim}
 paste(x, collapse = "\n")
\end{verbatim}
If we want to specify this in a call to \SFunction{lapply}, we cannot
simply use the \SFunction{paste} function. Instead, we need to also
have it use the \SArg{collapse} argument. We can do this in two
ways. A natural way is to define a new function that simply calls
\SFunction{paste}.
\begin{verbatim}
 lapply(l, function(x) paste(x, collapse="\n"))
\end{verbatim}
We can do better however. \SFunction{lapply} takes arbitrary
additional arguments via its $\ldots$ argument. These arguments are
passed directly to the function calls for each element. So this allows
us to pass in additional arguments like \SArg{collapse}. So we can
write this expression now as
\begin{verbatim}
 lapply(l, paste, collapse="\n")
\end{verbatim}
So the \SArg{collapse} argument is given to \SFunction{lapply}, but is
then passed on to each call to \SFunction{paste}. This is likely to be
marginally faster than the earlier version because there is one less
function call per element. We call \SFunction{paste} directly rather
than a function that calls \SFunction{paste}. But this is a second
order consideration at this stage.

Lists are very useful when we want to do a number of iterations and
store the results from each. The bootstrap or any form of simulation
is a good example. The example above suggests that if we wanted to
loop over different sample sizes - say 10, 100, 1000, 10000 - and
compute samples of that size, we might do this and store the results
in a list. Many people are included to try to save the results of each
iteration to a variable with a name made up by pasting a name and the
sample size together. This can be done, but it is not a very good way.
\begin{verbatim}
for(i in c(10, 100, 1000, 10000)) {
  x = rnorm(i)
  assign(paste("sample", i, sep="."))
}
\end{verbatim}
Then we end up with the results in the variables
\SVariable{sample.10}, \SVariable{sample.100}, \SVariable{sample.1000}
and \SVariable{sample.10000}. This will overwrite any existing
variables having these names. It is also hard to deal with the
collection of results as a collection. Instead, they are distinct
variables.

A better way to do this is as follows. 
\begin{verbatim}
ans <- list()
for(i in c(10, 100, 1000, 10000)) {
 ans[[paste("sample", i, sep=".")]] <- rnorm(i)
}
\end{verbatim}
Now we end up with a list containing the 4 sample vectors. One of
the nice things we can do here is use \SFunction{lapply} to compute on
the elements as a collection: e.g.
\begin{verbatim}
> lapply(ans, mean)
\end{verbatim}
as before.

Perhaps the nicest way to do these iterative computations is to use
\SFunction{lapply} on the vector of sample sizes.
\begin{verbatim}
> ans = lapply(c(10, 100, 1000, 10000), rnorm)
\end{verbatim}
We lose the names, but we can put them on ourselves after the
computation. We do avoid having to declare a global variable
(\SVariable{ans}) and then add to it within each iteration, and the
names are very important in some contexts.

Just to show what we might do in a call to \SFunction{lapply}, let's
create a histogram of each of the 4 samples.
\begin{verbatim}
> par(mfrow=c(2,2))
> lapply(ans, hist)
\end{verbatim}
Here we split the graphics screen (which will be created automatically
if necessary) into 2 rows and 2 columns and then use the
\SFunction{hist} to create the individual histograms. We would
probably want to ensure that they had the same scale and the right
title and axis labels.
\begin{verbatim}
> lapply(ans, function(x) 
               hist(x, xlab="",
                    main=paste("Sample size", length(x))))
\end{verbatim}


There is one other detail in using \SFunction{lapply}. We mentioned
that it returns a list containing the new elements. If all the
elements have the same type, it is often much more convenient to have
them as a vector and not a list. Our example of when we computed the
mean of the samples is illustrative. Suppose we had 1000 samples in
our list, each of sample size 200. Then we might want to compute
different statistics on these samples and look at their
distributions. Let's do this by looking at the scatter-plot of means
and medians. First we generate our 1000 samples
\begin{verbatim}
> samples = lapply(1:1000, function(x) rnorm(200))
\end{verbatim}
Now, if we use \SFunction{lapply} to compute the medians and the
means, we will end up with two lists of length 1000. Unfortunately, to
display a scatterplot of these statistics, we need vectors, not
lists. (See the help page for \SFunction{plot}.) So what can we do?

One thing to do is call \SFunction{unlist}. This will unravel the
elements in the list and try to remove their structure and create a
vector. In this case, this will work nicely.
\begin{verbatim}
> unlist(lapply(samples, mean))
\end{verbatim}
In other cases, we have to be careful only to unlist at the
top-level. For example, if we have a list of lists, then we may not
want to unravel the entire two levels, but just the first. (See the
\SArg{recursive} argument for \SFunction{unlist}.)

A better apporach in many cases is to use the function
\SFunction{sapply}. This is the same as \SFunction{lapply} but it
attempts to coerce the result into a vector. If it can't do the
coercion, it simply returns the result as a list, as would
\SFunction{lapply}. So \SFunction{sapply} is exactly what we want
here. Our plot is easily created as
\begin{verbatim}
> plot(sapply(samples, mean), sapply(samples, median))
\end{verbatim}
and this gives us a sense of the relationship between the mean and
the median for standard normal distributions with samples of size
200.

\subsection{Data frames}


\section{Matrices}
The focus here is more on data frames than matrices because data
frames are a richer, more appropriate way to think about observed
data. However, since matrices arise within computational statistics a
lot, it is good to understand the basics. We can create a matrix in S
using the \SFunction{matrix} function. We give this values for the
elements, the number of rows and the number of columns.
\begin{verbatim}
> matrix(1:6, 2, 3)
     [,1] [,2] [,3]
[1,]    1    3    5
[2,]    2    4    6
\end{verbatim}
Note that the values (1, 2, 3, 4, 5, 6) are arranged column-wise. If
we wanted to arrange them row-wise, we could use the byRow argument.
\begin{verbatim}
> x = matrix(1:6, 2, 3, byrow = TRUE)
\end{verbatim}
Because of the recycling rule for vectors, we can give fewer values
than are needed. \SFunction{matrix} uses the number of rows and
columns to determine how many values it needs and recycles
appropriately. For example,
\begin{verbatim}
> matrix(NA, 2, 3)
\end{verbatim}
creates a matrix of NAs, i.e. missing values. 

We can even omit either dimension if we specify the correct number of
values. For example,
\begin{verbatim}
> matrix(1:6, , 3)
\end{verbatim}
omits the number of rows, and R infers that it is 2. 

Now that we know one way to create a matrix, let's think about what it
is in R. Essentially, it is a vector with additional information about
the dimensions of the matrix. The dimensions are stored as an integer
vector of length 2. This additional information is stored in a general
"attributes" field that we can associate with any R object. We can
query this value using the \SFunction{dim} function.
\begin{verbatim}
> dim(matrix(1:6, , 3))
[1] 2 3
\end{verbatim}
We can even assign a value to the dimension to change the ``shape'' of
the matrix.
\begin{verbatim}
> x = matrix(1:6, , 3)
   [,1] [,2] [,3]
[1,]    1    3    5
[2,]    2    4    6
> x
> dim(x) <- c(3, 2)
x
     [,1] [,2]
[1,]    1    4
[2,]    2    5
[3,]    3    6
\end{verbatim}
This is another way to create matrices. 

From the perspective of a matrix, the fact that it is a vector has a
very strong implication. Being a vector, a matrix in R can only
contain values or elements of the same type. This is like its
mathematical counterpart, and it means that we cannot mix character
elements with numbers or logicals. As we saw for vectors, if we
combine elements of different basic types, they get coerced into the
common form that doesn't lose information. This is rarely desirable
and this is where data frames are more appropriate and useful as we
shall see.

We do get desirable features from a matrix being a vector with
dimensions. For example, we can simply perform arithmetic on two
matrices of the right dimensions using the basic vector operations.
\begin{verbatim}
> matrix(1:4, 2, 2) + matrix(101:104, 2, 2)
     [,1] [,2]
[1,]  102  106
[2,]  104  108
> matrix(1:4, 2, 2)^3
     [,1] [,2]
[1,]    1   27
[2,]    8   64
\end{verbatim}


As with vectors, it is often convenient to supply names to label the
elements. In the case of matrices, we have two dimensions and so two
sets of names, one for the rows and one for the columns. We can access
the names using \SFunction{rownames} and \SFunction{colnames}. These
are actually stored together as a list containing two character
vectors of the appropriate lengths. They are again stored in the
attributes part of the object. We can access them together using the
\SFunction{dimnames} function meaning, of course, the dimension names.

One of the things we sometimes want to do on a matrix is to apply a
function to each of the rows or each of the columns. This is like a
vectorized operation that operates on the entire collection of
elements, but for a matrix there are times we want to respect the two
dimensional structure and apply the function to the different
collection of elements given by the rows or the columns. The function
\SFunction{apply} does this for us. We give it the matrix of interest,
the dimension we want to sweep over (i.e. the rows or the columns) and
a function that takes in a vector and returns a value. Let's take the
simple matrix we have above
\begin{verbatim}
> x = matrix(1:6, 2, 3)
\end{verbatim}
Now, we can sum the elements in each row using \SFunction{apply} in
the following way:
\begin{verbatim}
> apply(x, 1, sum)
[1]  9 12
\end{verbatim}
One way to remember which dimension to specify is to think about which
one we want left with us. And 1 refers to rows and 2 refers to
columns. We can use other functions, and indeed these functions can
return complicated objects, not just simple vectors of length 1.

The apply functions are very powerful. They work on matrices, and we
can use them on simple vectors also. They remove the need for verbose
looping constructs such as
\begin{verbatim}
ans <- numeric(nrow(x))
for(i in 1:nrow(x)) {
 ans[i] <- sum(x[i,])
}
\end{verbatim}
which is the equivalent to the \SFunction{apply} command in the
previous paragraph. And we shall see that the different forms of the
\SFunction{apply} functions are very important for operating on lists.

\subsection{Arrays}
A little thought about the fact that matrices are simply vectors with
an associated dimension vector might lead to thinking about
multi-dimensional matrices or {\em{arrays}}. We can use the same
structure and provide a dimension vector of length k to specify a k
dimensional array.
\begin{verbatim}
> array(1:60, c(3, 4, 5))
\end{verbatim}
This creates a collection of five 3 by 4 matrices. Of course, we can
look at this along any dimension and see it also as a collection of
three 4 x 5 matrices, or four 3 x 5 matrices.

And we can use the \SFunction{apply} function, this time with multiple
dimensions. Again, using the rule that we specify what dimensions we
want to be left with, we perform an operation along the other
dimensions such as
\begin{verbatim}
> apply(array(1:60, c(3, 4, 5)), c(1, 3), sum)
     [,1] [,2] [,3] [,4] [,5]
[1,]   22   70  118  166  214
[2,]   26   74  122  170  218
[3,]   30   78  126  174  222
\end{verbatim}
to end up with a 3 x 5 matrix collapse across the middle dimension of
4 matrices.

Similarly, we collapse the second and third dimension in the following
command.
\begin{verbatim}
> apply(array(1:60, c(3, 4, 5)), c(1), sum)
[1] 590 610 630
\end{verbatim}


Some functions to look at for operating on matrices in R are:
\SFunction{dimnames}, \SFunction{t}, \SFunction{eigen},
\SFunction{diag}, \SFunction{solve}.
